{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b46c363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pynput\n",
      "  Downloading pynput-1.7.3-py2.py3-none-any.whl (99 kB)\n",
      "Requirement already satisfied: six in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from pynput) (1.15.0)\n",
      "Installing collected packages: pynput\n",
      "Successfully installed pynput-1.7.3\n"
     ]
    }
   ],
   "source": [
    "! pip install pynput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9689b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cvzone in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from cvzone) (4.5.3.56)\n",
      "Requirement already satisfied: numpy in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from cvzone) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "! pip install cvzone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52ef8733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (0.8.7.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from mediapipe) (1.19.5)\n",
      "Requirement already satisfied: absl-py in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from mediapipe) (0.13.0)\n",
      "Requirement already satisfied: six in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from mediapipe) (1.15.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from mediapipe) (0.36.2)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from mediapipe) (3.17.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from mediapipe) (3.4.2)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\insa\\appdata\\roaming\\python\\python38\\site-packages (from mediapipe) (4.5.3.56)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from matplotlib->mediapipe) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from matplotlib->mediapipe) (8.3.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install mediapipe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ff851a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting HandTrackingModule\n",
      "  Downloading HandTrackingModule-0.1.tar.gz (1.7 kB)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from HandTrackingModule) (4.5.3.56)\n",
      "Requirement already satisfied: numpy in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from HandTrackingModule) (1.19.5)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from HandTrackingModule) (0.8.7.2)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\insa\\appdata\\roaming\\python\\python38\\site-packages (from mediapipe->HandTrackingModule) (4.5.3.56)\n",
      "Requirement already satisfied: absl-py in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from mediapipe->HandTrackingModule) (0.13.0)\n",
      "Requirement already satisfied: six in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from mediapipe->HandTrackingModule) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from mediapipe->HandTrackingModule) (3.17.3)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from mediapipe->HandTrackingModule) (21.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from mediapipe->HandTrackingModule) (3.4.2)\n",
      "Requirement already satisfied: wheel in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from mediapipe->HandTrackingModule) (0.36.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from matplotlib->mediapipe->HandTrackingModule) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from matplotlib->mediapipe->HandTrackingModule) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from matplotlib->mediapipe->HandTrackingModule) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from matplotlib->mediapipe->HandTrackingModule) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\insa\\anaconda3\\envs\\insa\\lib\\site-packages (from matplotlib->mediapipe->HandTrackingModule) (8.3.1)\n",
      "Building wheels for collected packages: HandTrackingModule\n",
      "  Building wheel for HandTrackingModule (setup.py): started\n",
      "  Building wheel for HandTrackingModule (setup.py): finished with status 'done'\n",
      "  Created wheel for HandTrackingModule: filename=HandTrackingModule-0.1-py3-none-any.whl size=2295 sha256=6d953d0581c8d0bd1171b591d51b97e454bee9c77b6aac2946319dc32c1d8a3d\n",
      "  Stored in directory: c:\\users\\insa\\appdata\\local\\pip\\cache\\wheels\\99\\9f\\31\\b0d153b7b9df523f43aa3898a6d28a09074eabaeeb7a9745bb\n",
      "Successfully built HandTrackingModule\n",
      "Installing collected packages: HandTrackingModule\n",
      "Successfully installed HandTrackingModule-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install HandTrackingModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31102f1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HandDetector' object has no attribute 'findPosition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-2240cb1881d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindHands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mlmList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbboxInfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindPosition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdrawAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuttonList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HandDetector' object has no attribute 'findPosition'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import cvzone\n",
    "from pynput.keyboard import Controller\n",
    "import mediapipe as mp\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "\n",
    "detector = HandDetector(detectionCon=0.8)\n",
    "keys = [[\"Q\", \"W\", \"E\", \"R\", \"T\", \"Y\", \"U\", \"I\", \"O\", \"P\"],\n",
    "        [\"A\", \"S\", \"D\", \"F\", \"G\", \"H\", \"J\", \"K\", \"L\", \";\"],\n",
    "        [\"Z\", \"X\", \"C\", \"V\", \"B\", \"N\", \"M\", \",\", \".\", \"/\"]]\n",
    "finalText = \"\"\n",
    "\n",
    "keyboard = Controller()\n",
    "\n",
    "\n",
    "def drawAll(img, buttonList):\n",
    "    for button in buttonList:\n",
    "        x, y = button.pos\n",
    "        w, h = button.size\n",
    "        cvzone.cornerRect(img, (button.pos[0], button.pos[1], button.size[0], button.size[1]),\n",
    "                          20, rt=0)\n",
    "        cv2.rectangle(img, button.pos, (x + w, y + h), (255, 0, 255), cv2.FILLED)\n",
    "        cv2.putText(img, button.text, (x + 20, y + 65),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 4, (255, 255, 255), 4)\n",
    "    return img\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "class Button():\n",
    "    def __init__(self, pos, text, size=[85, 85]):\n",
    "        self.pos = pos\n",
    "        self.size = size\n",
    "        self.text = text\n",
    "\n",
    "buttonList = []\n",
    "for i in range(len(keys)):\n",
    "    for j, key in enumerate(keys[i]):\n",
    "        buttonList.append(Button([100 * j + 50, 100 * i + 50], key))\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = detector.findHands(img)\n",
    "    lmList, bboxInfo = detector.findPosition(img, draw = False)\n",
    "    img = drawAll(img, buttonList)\n",
    "\n",
    "    if lmList:\n",
    "        for button in buttonList:\n",
    "            x, y = button.pos\n",
    "            w, h = button.size\n",
    "\n",
    "            if x < lmList[8][0] < x + w and y < lmList[8][1] < y + h:\n",
    "                cv2.rectangle(img, (x - 5, y - 5), (x + w + 5, y + h + 5), (175, 0, 175), cv2.FILLED)\n",
    "                cv2.putText(img, button.text, (x + 20, y + 65),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 4, (255, 255, 255), 4)\n",
    "                l, _, _ = detector.findDistance(8, 12, img, draw=False)\n",
    "                print(l)\n",
    "\n",
    "                ## when clicked\n",
    "                if l < 30:\n",
    "                    keyboard.press(button.text)\n",
    "                    cv2.rectangle(img, button.pos, (x + w, y + h), (0, 255, 0), cv2.FILLED)\n",
    "                    cv2.putText(img, button.text, (x + 20, y + 65),\n",
    "                                cv2.FONT_HERSHEY_PLAIN, 4, (255, 255, 255), 4)\n",
    "                    finalText += button.text\n",
    "                    sleep(0.15)\n",
    "\n",
    "    cv2.rectangle(img, (50, 350), (700, 450), (175, 0, 175), cv2.FILLED)\n",
    "    cv2.putText(img, finalText, (60, 430),\n",
    "                cv2.FONT_HERSHEY_PLAIN, 5, (255, 255, 255), 5)\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67b68063",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ad3d3de506a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# Draw the face mesh annotations on the image.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_RGB2BGR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_face_landmarks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mface_landmarks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_face_landmarks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# For static images:\n",
    "IMAGE_FILES = []\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,\n",
    "    max_num_faces=1,\n",
    "    min_detection_confidence=0.5) as face_mesh:\n",
    "  for idx, file in enumerate(IMAGE_FILES):\n",
    "    image = cv2.imread(file)\n",
    "    # Convert the BGR image to RGB before processing.\n",
    "    results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Print and draw face mesh landmarks on the image.\n",
    "    if not results.multi_face_landmarks:\n",
    "      continue\n",
    "    annotated_image = image.copy()\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "      print('face_landmarks:', face_landmarks)\n",
    "      mp_drawing.draw_landmarks(\n",
    "          image=annotated_image,\n",
    "          landmark_list=face_landmarks,\n",
    "          connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "          landmark_drawing_spec=None,\n",
    "          connection_drawing_spec=mp_drawing_styles\n",
    "          .get_default_face_mesh_tesselation_style())\n",
    "      mp_drawing.draw_landmarks(\n",
    "          image=annotated_image,\n",
    "          landmark_list=face_landmarks,\n",
    "          connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "          landmark_drawing_spec=None,\n",
    "          connection_drawing_spec=mp_drawing_styles\n",
    "          .get_default_face_mesh_contours_style())\n",
    "    cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)\n",
    "\n",
    "# For webcam input:\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display, and convert\n",
    "    # the BGR image to RGB.\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = face_mesh.process(image)\n",
    "\n",
    "    # Draw the face mesh annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    if results.multi_face_landmarks:\n",
    "      for face_landmarks in results.multi_face_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=image,\n",
    "            landmark_list=face_landmarks,\n",
    "            connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles\n",
    "            .get_default_face_mesh_tesselation_style())\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=image,\n",
    "            landmark_list=face_landmarks,\n",
    "            connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles\n",
    "            .get_default_face_mesh_contours_style())\n",
    "    cv2.imshow('MediaPipe FaceMesh', image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32060b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ad3d3de506a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m     min_tracking_confidence=0.5) as face_mesh:\n\u001b[0;32m     47\u001b[0m   \u001b[1;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m       \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Ignoring empty camera frame.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# For static images:\n",
    "IMAGE_FILES = []\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,\n",
    "    max_num_faces=1,\n",
    "    min_detection_confidence=0.5) as face_mesh:\n",
    "  for idx, file in enumerate(IMAGE_FILES):\n",
    "    image = cv2.imread(file)\n",
    "    # Convert the BGR image to RGB before processing.\n",
    "    results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Print and draw face mesh landmarks on the image.\n",
    "    if not results.multi_face_landmarks:\n",
    "      continue\n",
    "    annotated_image = image.copy()\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "      print('face_landmarks:', face_landmarks)\n",
    "      mp_drawing.draw_landmarks(\n",
    "          image=annotated_image,\n",
    "          landmark_list=face_landmarks,\n",
    "          connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "          landmark_drawing_spec=None,\n",
    "          connection_drawing_spec=mp_drawing_styles\n",
    "          .get_default_face_mesh_tesselation_style())\n",
    "      mp_drawing.draw_landmarks(\n",
    "          image=annotated_image,\n",
    "          landmark_list=face_landmarks,\n",
    "          connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "          landmark_drawing_spec=None,\n",
    "          connection_drawing_spec=mp_drawing_styles\n",
    "          .get_default_face_mesh_contours_style())\n",
    "    cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)\n",
    "\n",
    "# For webcam input:\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display, and convert\n",
    "    # the BGR image to RGB.\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = face_mesh.process(image)\n",
    "\n",
    "    # Draw the face mesh annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    if results.multi_face_landmarks:\n",
    "      for face_landmarks in results.multi_face_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=image,\n",
    "            landmark_list=face_landmarks,\n",
    "            connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles\n",
    "            .get_default_face_mesh_tesselation_style())\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=image,\n",
    "            landmark_list=face_landmarks,\n",
    "            connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles\n",
    "            .get_default_face_mesh_contours_style())\n",
    "    cv2.imshow('MediaPipe FaceMesh', image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bf798d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
