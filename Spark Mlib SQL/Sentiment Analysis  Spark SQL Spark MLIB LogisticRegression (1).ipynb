{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8c368bd",
   "metadata": {},
   "source": [
    "# Import module and create sparksession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "752a8c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import* # function pour calculer somme etc\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover\n",
    "# sparksession\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Sentiment Analysis Spark').config(\"spark.some.config.option\", \"some-value\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8384248a",
   "metadata": {},
   "source": [
    "# Read datafile into SparkDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb051e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---------------+---------------------------------+\n",
      "|ItemID|Sentiment|SentimentSource|SentimentText                    |\n",
      "+------+---------+---------------+---------------------------------+\n",
      "|1038  |1        |Sentiment140   |that film is fantastic #brilliant|\n",
      "|1804  |1        |Sentiment140   |this music is really bad #myband |\n",
      "|1693  |0        |Sentiment140   |winter is terrible #thumbs-down  |\n",
      "+------+---------+---------------+---------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read ccsv file into dataframe with autatically inferredschema\n",
    "create_csv = spark.read.csv(r'C:\\v_data\\tweets.csv', inferSchema =True, header =True)\n",
    "create_csv.show(truncate=False, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8e8b31",
   "metadata": {},
   "source": [
    "# Selected the related data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e88c9e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----+\n",
      "|SentimentText                    |label|\n",
      "+---------------------------------+-----+\n",
      "|that film is fantastic #brilliant|1    |\n",
      "|this music is really bad #myband |1    |\n",
      "|winter is terrible #thumbs-down  |0    |\n",
      "|this game is awful #nightmare    |0    |\n",
      "|I love jam #loveit               |1    |\n",
      "+---------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = create_csv.select(\"SentimentText\", col(\"Sentiment\").cast(\"Int\").alias(\"label\"))\n",
    "data.show(truncate = False,n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fefd04d",
   "metadata": {},
   "source": [
    "# divide data into training and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbb46328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data rows: 1306 ; Testing data rows: 626\n"
     ]
    }
   ],
   "source": [
    "#divide data, 70% for training, 30% for testing\n",
    "divideData= data.randomSplit([0.7, 0.3])\n",
    "trainingData= divideData[0]#index 0 = data training\n",
    "testingData =divideData[1]  #index 1 = data testing\n",
    "train_rows = trainingData.count()\n",
    "test_rows= testingData.count()\n",
    "print (\"Training data rows:\", train_rows, \"; Testing data rows:\", test_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408c99b5",
   "metadata": {},
   "source": [
    "# Prepare training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate \"SentimentText\" into individual words using tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26bf1bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----+------------------------------+\n",
      "|SentimentText            |label|SentimentWords                |\n",
      "+-------------------------+-----+------------------------------+\n",
      "|I adore cheese #bestever |1    |[i, adore, cheese, #bestever] |\n",
      "|I adore cheese #loveit   |1    |[i, adore, cheese, #loveit]   |\n",
      "|I adore cheese #toptastic|1    |[i, adore, cheese, #toptastic]|\n",
      "+-------------------------+-----+------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"SentimentText\", outputCol=\"SentimentWords\")\n",
    "tokenizedTrain= tokenizer.transform(trainingData)\n",
    "tokenizedTrain.show(truncate=False,n =3)#Show top 5 rows and full column contents (PySpark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd85a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords(unimportant words to be features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bed692a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----+------------------------------+---------------------------+\n",
      "|SentimentText            |label|SentimentWords                |MeaningFullWords           |\n",
      "+-------------------------+-----+------------------------------+---------------------------+\n",
      "|I adore cheese #bestever |1    |[i, adore, cheese, #bestever] |[adore, cheese, #bestever] |\n",
      "|I adore cheese #loveit   |1    |[i, adore, cheese, #loveit]   |[adore, cheese, #loveit]   |\n",
      "|I adore cheese #toptastic|1    |[i, adore, cheese, #toptastic]|[adore, cheese, #toptastic]|\n",
      "+-------------------------+-----+------------------------------+---------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swr= StopWordsRemover(inputCol = tokenizer.getOutputCol(), outputCol=\"MeaningFullWords\")\n",
    "swrRemovedTrain= swr.transform(tokenizedTrain)\n",
    "swrRemovedTrain.show(truncate=False, n= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ff99ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------+-------------------------------------------+\n",
      "|label|MeaningFullWords           |features                                   |\n",
      "+-----+---------------------------+-------------------------------------------+\n",
      "|1    |[adore, cheese, #bestever] |(262144,[1689,91011,100089],[1.0,1.0,1.0]) |\n",
      "|1    |[adore, cheese, #loveit]   |(262144,[1689,100089,254974],[1.0,1.0,1.0])|\n",
      "|1    |[adore, cheese, #toptastic]|(262144,[1689,42010,100089],[1.0,1.0,1.0]) |\n",
      "+-----+---------------------------+-------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Converting words feature into numerical feature.\n",
    "#In Spark 2.2.1,it is implemented in HashingTF funtion using Austin Appleby's MurmurHash 3 algorithm\n",
    "hashTF= HashingTF(inputCol=swr.getOutputCol(), outputCol='features')\n",
    "numericTrainingData= hashTF.transform(swrRemovedTrain).select('label', 'MeaningFullWords', 'features')\n",
    "numericTrainingData.show(truncate=False, n =3 )\n",
    "#hashTF = HashingTF(inputCol=swr.getOutputCol(), outputCol=\"features\")\n",
    "#numericTrainData = hashTF.transform(SwRemovedTrain).select(\n",
    "#    'label', 'MeaningfulWords', 'features')\n",
    "#numericTrainData.show(truncate=False, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa23ea",
   "metadata": {},
   "source": [
    "# train our classifier model using traindata with  model logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b204ac6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function JavaWrapper.__del__ at 0x00000170C9A0C040>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\INSA\\anaconda3\\envs\\INSA\\lib\\site-packages\\pyspark\\ml\\wrapper.py\", line 39, in __del__\n",
      "    if SparkContext._active_spark_context and self._java_obj is not None:\n",
      "AttributeError: 'StopWordsRemover' object has no attribute '_java_obj'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training is OK\n"
     ]
    }
   ],
   "source": [
    "lr= LogisticRegression(labelCol='label', featuresCol='features', maxIter=10, regParam=0.01)\n",
    "model= lr.fit(numericTrainingData)\n",
    "print(\"training is OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed6e19b",
   "metadata": {},
   "source": [
    "# prepare testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc7840be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+-----+----------------------------------------+\n",
      "|SentimentText                     |label|SentimentWords                          |\n",
      "+----------------------------------+-----+----------------------------------------+\n",
      "|I adore cheese #brilliant         |1    |[i, adore, cheese, #brilliant]          |\n",
      "|I adore cheese #favorite          |1    |[i, adore, cheese, #favorite]           |\n",
      "|I adore cheese #thumbs-up         |1    |[i, adore, cheese, #thumbs-up]          |\n",
      "|I adore classical music #favorite |1    |[i, adore, classical, music, #favorite] |\n",
      "|I adore classical music #thumbs-up|1    |[i, adore, classical, music, #thumbs-up]|\n",
      "+----------------------------------+-----+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizedTest = tokenizer.transform(testingData)\n",
    "tokenizedTest.show(truncate=False, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffae2e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "swrRemovedTest= swr.transform(tokenizedTest) # unimportant words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3446971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------------------------+--------------------------------------------------------+\n",
      "|label|MeaningFullWords                    |features                                                |\n",
      "+-----+------------------------------------+--------------------------------------------------------+\n",
      "|1    |[adore, cheese, #brilliant]         |(262144,[1689,45361,100089],[1.0,1.0,1.0])              |\n",
      "|1    |[adore, cheese, #favorite]          |(262144,[1689,100089,108624],[1.0,1.0,1.0])             |\n",
      "|1    |[adore, cheese, #thumbs-up]         |(262144,[1689,88825,100089],[1.0,1.0,1.0])              |\n",
      "|1    |[adore, classical, music, #favorite]|(262144,[100089,102383,108624,131250],[1.0,1.0,1.0,1.0])|\n",
      "+-----+------------------------------------+--------------------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numericTestData= hashTF.transform(swrRemovedTest).select('label', 'MeaningFullWords', 'features') # wordsintonumeric\n",
    "numericTestData.show(truncate=False, n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1735a711",
   "metadata": {},
   "source": [
    "# Predict testing data and calculate the accuracy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1917172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml\n",
    "##val denseVector = r.getAs[org.apache.spark.ml.linalg.SparseVector](\"features\").toDense\n",
    "#org.apache.spark.mllib.linalg.Vectors.fromML(denseVector)\n",
    "#import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS\n",
    "#import org.apache.spark.mllib.linalg.Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ad3f1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: --driver-memory\n"
     ]
    }
   ],
   "source": [
    "! pip install spark-1.4.1-bin-hadoop2.6/bin/spark-submit --driver-memory 5g --packages com.databricks:spark-csv_2.10:1.1.0 fbi_spark.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b9a37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(numericTestData)\n",
    "predictionFinal = prediction.select('label', 'MeaningFullWords', 'features')\n",
    "predictionFinal.show(truncate=False, n=5)\n",
    "correctPrediction = predictionFinal.filter(\n",
    "    predictionFinal['prediction'] == predictionFinal['Label']).count()\n",
    "totalData = predictionFinal.count()\n",
    "print(\"correct prediction:\", correctPrediction, \", total data:\", totalData, \n",
    "      \", accuracy:\", correctPrediction/totalData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
